---
title: "p8105_hw2_ys3924"
author: "YISU"
date: "2024-10-02"
output: github_document
---

```{r setup, message=FALSE}
library(tidyverse)
library(readxl)
```

# Problem 1

## Read in and clean NYC Transit data

```{r, message=FALSE, warning=FALSE}
NYC_transit = 
  read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") |>
  janitor::clean_names() |>
  select(line:entry, vending, ada) |>
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

The NYC Transit dataset contains subway line, station name, station latitude and longitude, routes served, entry, vending, entrance type, and ADA compliance.

In my data cleaning process, I first used janitor::clean_names() function to convert all column names to lowercase. Then I selected the key factors needed for this analysis. Finally, I transformed the entry variable from a "YES"/"NO" character format to a logical TRUE/FALSE. 

There are 1868 rows and 19 columns for this resulting dataset. 

## Count distinct stations

```{r}
num_distinct_stations = NYC_transit |>
  distinct(station_name, line) |>
  nrow()
```

There are `r num_distinct_stations` distinct stations.

## Count ADA stations 

```{r}
num_ada = NYC_transit |>
  filter(ada == TRUE) |>
  distinct(station_name, line) |>
  nrow()
```

There are `r num_ada` ADA compliant stations.

## Calculate proportion of station entrances / exits without vending allow entrance

```{r}
num_no_vending = NYC_transit |>
  filter(vending == "NO") |>
  nrow()
proportion_no_vending = num_no_vending / nrow(NYC_transit)
```

The proportion of station entrances / exits without vending allow entrance is `r proportion_no_vending`.


# Problem 2

## Read in and clean Mr.Trash Wheel data

```{r}
mr_trash_wheel = read_excel("data/202409 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", na = c("NA", ".", ""), skip = 1) |>
  janitor::clean_names() |>
  select(dumpster:homes_powered) |>
  mutate(sports_balls = as.integer(round(sports_balls, 0)),
         trash_wheel_name = "Mr. Trash Wheel",
         year = as.numeric(year)) |>
  filter(!is.na(dumpster)) |>
  relocate(trash_wheel_name, dumpster)
```

## Read in and clean Professor Trash Wheel data

```{r}
professor_trash_wheel = read_excel("data/202409 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", na = c("NA", ".", ""), skip = 1) |>
  janitor::clean_names() |>
  mutate(trash_wheel_name = "Professor Trash Wheel") |>
  filter(!is.na(dumpster)) |>
  slice(1:(n() - 1)) |>
  relocate(trash_wheel_name, dumpster)
```

## Read in and clean Gwynnda Trash Wheel data

```{r}
gwynnda_trash_wheel = read_excel("data/202409 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", na = c("NA", ".", ""), skip = 1) |>
  janitor::clean_names() |>
  mutate(trash_wheel_name = "Gwynnda Trash Wheel") |>
  filter(!is.na(dumpster)) |>
  relocate(trash_wheel_name, dumpster)
```

## Combine the dataset

```{r}
full_trash_wheel = bind_rows(mr_trash_wheel, professor_trash_wheel, gwynnda_trash_wheel)
num_rows = nrow(full_trash_wheel)
num_cols = ncol(full_trash_wheel)
```

The dataset contains information on trash collection by Mr.Trash Wheel, Professor Trash Wheel, and Gwynnda Trash Wheel. There are `r num_rows` rows and `r num_cols` columns in this dataset. The key variables include year, weight_tons, volumne_cubic_yard, plastic bottles, cigarette_butts, and homes_powered. 

```{r}
prof_total_weight = professor_trash_wheel |>
  summarise(prof_total_weight = sum(weight_tons, na.rm = TRUE)) |>
  pull(prof_total_weight)
gwynnda_cigarette_butts <- gwynnda_trash_wheel |>
  filter(month == "June" & year == 2022) |>
  summarise(gwynnda_cigarette_butts = sum(cigarette_butts, na.rm = TRUE)) |>
  pull(gwynnda_cigarette_butts)
```

The total weight of trash collected by Professor Trash Wheel was `r prof_total_weight`. The total number of cigarette butts collected by Gwynnda in June of 2022 was `r gwynnda_cigarette_butts`.

# Problem 3

## Read in and clean the datasets

```{r, message=FALSE}
bakers = read_csv("./data/gbb_datasets/bakers.csv") |>
  janitor::clean_names()   |>          
  rename(baker = baker_name) |>
  separate(baker, into = c("baker", "last_name"), sep = " ", extra = "drop") 
bakes = read_csv("./data/gbb_datasets/bakes.csv") |>
  janitor::clean_names()
results = read_csv("./data/gbb_datasets/results.csv", skip = 1) |>
  janitor::clean_names() |>
  janitor::row_to_names(row_number = 1) |>
  mutate(series = as.numeric(series),
         episode = as.numeric(episode))
```
In my data cleaning process, I first used janitor::clean_names() function to convert all column names to lowercase. For the bakers dataset, I renamed the baker_names column to baker and split the full name, retaining only the first name to ensure consistency with the other datasets. For the results dataset, I skipped the first row during the import process since it contains NA values in all columns. I then set the actual row with column names as the proper column headers. Finally, I changed the series and episode column in results dataset to numeric to keep consistency.



## Check for completeness and correctness across datasets 
```{r}
anti_join(bakers, bakes)
anti_join(bakes, bakers)
anti_join(bakers, results)
```

By looking at above anti_join() results, the baker "Jo" from series 2 is not matched in results dataset. In bakes dataset, their name appears with quotes, which should be fixed. Also, bakes dataset lacks data from series 9 and 10, so bakers and results from those series are missing.

```{r}
bakes <- bakes |>
  mutate(baker = ifelse(baker == "\"Jo\"", "Jo", baker))
```
In order to solve the problem, I replaced "Jo" with Jo in the bakes dataset.






